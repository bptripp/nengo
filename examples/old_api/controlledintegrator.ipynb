{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Nengo Example: Controlled Integrator\n",
      "\n",
      "A controlled integrator is a circuit that acts on two signals:\n",
      "\n",
      "1. Input - the signal being integrated\n",
      "2. Control - the control signal to the integrator\n",
      "\n",
      "A controlled integrator accumulates input, but its state can be directly manipulated by the control signal.\n",
      "We can write the dynamics of a simple controlled integrator like this:\n",
      "\n",
      "$$\n",
      "\\dot{a}(t) = \\mathrm{control}(t) \\cdot a(t) + B \\cdot \\mathrm{input}(t)\n",
      "$$\n",
      "\n",
      "In this notebook, we will build a controlled intgrator with Leaky Integrate and Fire ([LIF](TODO)) neurons.\n",
      "The Neural Engineering Framework ([NEF](TODO)) equivalent equation for this integrator is:\n",
      "\n",
      "$$\n",
      "\\dot{a}(t) = \\mathrm{control}(t) \\cdot a(t) + \\tau \\cdot \\mathrm{input}(t).\n",
      "$$\n",
      "\n",
      "We call the coefficient $\\tau$ here a *recurrent time constant* because it governs the rate of integration.\n",
      "\n",
      "Network behaviour:\n",
      "`A = tau * Input + Input * Control`\n",
      "\n",
      "(MISSING: Network circuit diagram - can maybe generate this in-line?)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### do some setup before we start\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 1: Create the network\n",
      "\n",
      "We can use standard network-creation commands to begin creating our controlled integrator.\n",
      "We create a Network, and then we create a population of neurons (called an *ensemble*).\n",
      "This population of neurons will represent the state of our integrator, and the connections between the neurons in the ensemble will define the dynamics of our integrator."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nengo\n",
      "from nengo.old_api import Network, compute_transform\n",
      "\n",
      "tau = 0.1\n",
      "\n",
      "# Create the nengo model\n",
      "model = Network('Controlled Integrator')\n",
      "\n",
      "# Create the neuronal ensembles\n",
      "A = model.make_array('A', 225, 1, 2,            # Make a population with 225 neurons, \n",
      "                     radius = 1.5)              #   2 dimensions, and a larger radius \n",
      "                                                #   to accommodate large simulataneous \n",
      "                                                #   inputs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 2: Define the 'input' signal to integrate\n",
      "\n",
      "We will be running 1 second of simulation time, so we will use a Python function `input_func` to define our input signal for real values of time `t` from 0 to 1. We'll define our signal to be a step function using if-then-else code. Our piece-wise function sits at 0 until .2 seconds into the simulation, then jumps up to 5, back to 0, down to -10, back to 0, then up to 5, and then back to 0. Our integrator will respond by ramping up when the input is positive, and descending when the input is negative."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def input_func(t):              # Create a function that outputs\n",
      "    if   t < 0.2:  return 0     # 0 for t < 0.2\n",
      "    elif t < 0.3:  return 5     # 5 for 0.2 < t < 0.3\n",
      "    elif t < 0.44: return 0     # 0 for 0.3 < t < 0.44\n",
      "    elif t < 0.54: return -10   # -10 for 0.44 < t < 0.54\n",
      "    elif t < 0.8:  return 0     # 0 for 0.54 < t < 0.8\n",
      "    elif t < 0.9:  return 5     # 5 for 0.8 < t < 0.9\n",
      "    else:          return 0     # 0 for t > 0.9\n",
      "    \n",
      "t = np.linspace(0, 1, 101)\n",
      "plt.plot(t, map(input_func, t))\n",
      "plt.ylim((-11,11));"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We include this input function (`input_func`) into our neural model like this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define an input signal within our model\n",
      "model.make_input('Input', input_func)\n",
      " \n",
      "# Connect the Input signal to ensemble A.\n",
      "# The `transform` argument means \"connect real-valued signal \"Input\" to the\n",
      "# first of the two input channels of A.\"\n",
      "model.connect('Input', 'A',\n",
      "              transform=[[tau], [0]],\n",
      "              pstc=tau)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 3: Define the 'control' signal\n",
      "\n",
      "We also need to create a control signal that controls how the integrator behaves. We will make this signal 1 for the first part of the simulation, and 0.5 for the second part. This means that at the beginning of the simulation, the integrator will act as an optimal integrator, and partway though the simulation (at t = 0.6), it will switch to being a leaky integrator."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def control_func(t):            # Create a function that outputs\n",
      "    if   t < 0.6: return 1      # 1 for t < 0.65\n",
      "    else:         return 0.5    # 0.5 for t > 0.65\n",
      "    \n",
      "t = np.linspace(0, 1, 101)\n",
      "plt.plot(t, map(control_func, t))\n",
      "plt.ylim(0,1.1);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We add the control signal to the network like we added the input signal, but this this time we connect it to the second dimension of our neural population."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.make_input('Control', control_func)\n",
      "\n",
      "# -- Connect the \"Control\" signal to the second of A's two input channels\n",
      "#    using the `transform` matrix.\n",
      "model.connect('Control', 'A', transform=[[0], [1]], pstc=0.005)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 4: Define the integrator dynamics\n",
      "\n",
      "We set up integratorconnect population 'A' to itself.\n",
      "We set up feedback in the model to handle integration of the input.\n",
      "The time constant $\\tau$ on the recurrent weights affects both the rate and accuracy of integration, try adjusting it and look what happens.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a recurrent connection that first takes the product\n",
      "# of both dimensions in A (i.e., the value times the control)\n",
      "# and then adds this back into the first dimension of A using\n",
      "# a transform\n",
      "model.connect('A', 'A',\n",
      "              func=lambda x: x[0] * x[1],  # -- function is applied first to A\n",
      "              transform=[[1], [0]],        # -- transform converts function output to new state inputs\n",
      "              pstc=tau)\n",
      "\n",
      "# Make a probe to record both dimensions of A\n",
      "#p = model.make_probe('A', dt_sample=0.02, pstc=0.02)\n",
      "p = model.make_probe('A', dt_sample=0.001, pstc=0.02)\n",
      " \n",
      "# Run the model\n",
      "t_final = 1.4\n",
      "model.run(t_final)          # Run the model for 1.4 seconds\n",
      "\n",
      "A_data = p.get_data()       # get data about A's 2-D value\n",
      "value, control = A_data.T   # split A's data into it's two dimensions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Step 5: Plot and interpret the result"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot the value and control signals, along with the exact integral\n",
      "dt = 0.001\n",
      "input_sig = map(input_func, dt*np.arange(t_final/dt))\n",
      "control_sig = map(control_func, dt*np.arange(t_final/dt))\n",
      "ref = dt*np.cumsum(input_sig)\n",
      "t = lambda x: (t_final/float(len(x)))*np.arange(len(x))\n",
      "\n",
      "fig = plt.figure(figsize=(6,8))\n",
      "ax = fig.add_subplot(211)\n",
      "ax.plot(t(input_sig), input_sig)\n",
      "ax.set_ylim([-11,11])\n",
      "ax.set_ylabel('input')\n",
      "ax.legend(['input'], loc=3, frameon=False)\n",
      "\n",
      "ax = fig.add_subplot(212)\n",
      "ax.plot(t(ref), ref, 'k--')\n",
      "ax.plot(t(value), value)\n",
      "ax.plot(t(control), control)\n",
      "ax.set_ylim([-1.1,1.1])\n",
      "ax.set_xlabel('time [s]')\n",
      "ax.set_ylabel('x(t)')\n",
      "ax.legend(['exact', 'A[0] (value)', 'A[1] (control)'], loc=3, frameon=False);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The above plot shows the output of our system, specifically the (integrated) value stored by the A population, along with the control signal represented by the A population. The exact value of the integral, as performed by a perfect (non-neural) integrator, is shown for reference.\n",
      "\n",
      "When the control value is 1 (t < 0.6), the neural integrator performs near-perfect integration. However, when the control value drops to 0.5 (t > 0.6), the integrator becomes a leaky integrator. This means that in the absence of input, its stored value drifts towards zero. "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}